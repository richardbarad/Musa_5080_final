---
title: "MUSA_Final"
author: "Richard Barad"
date: "2023-12-04"
output: html_document
---

To add:
* Length of time established has been open for (based on business liscence data)
* Establishments that had previous critical or serious violations (based on historical data from 2010 - 2020)

```{r clear_environment, cache = TRUE, include = FALSE}

# Lists All Of The Objects In The Work Space
rm(list=ls())
```

```{r knitting_options, include = FALSE}
# Global Options For Knitting Chunks
knitr::opts_chunk$set(echo = T, messages = F, warning = F, error = F)
```

```{r import_libraries, include = FALSE}
library(tidyverse) # Data Science Workflow & Representation
library(tidycensus) # Load United States Census Boundary & Attribute Data
library(sf) # Standardized Way To Encode Spatial Vector Data
library(spdep) # Spatial Dependence: Weighting Schemes & Statistics
library(caret) # Classification and Regression Training
library(FNN) # Fast Nearest Neighbor Search Algorithms & Applications
library(RSocrata) # Download or Upload 'Socrata' Data Sets/Open Data Portals
library(viridis) # Colorblind-Friendly Color Maps Package
library(gridExtra) # Miscellaneous Functions for "Grid" Graphics
library(knitr) # General-Purpose Package for Dynamic Report Generation
library(kableExtra) # Construct Complex Table with 'Kable' and Pipe Syntax
library(plotROC) # Generate Useful ROC Curve Charts for Print and Interactive Use
library(pROC) # Display and Analyze Receiver Operating Characteristic Curves
library(lubridate) # Functions to Work with Date-Times and Time-Spans
library(ggpubr) # GGPLOT Based Publication Ready Plots
library(ggcorrplot) # Visualization of a Correlation Matrix Using GGPLOT2
library(matchmaker)
```

## Read the data using the Socrata API

I filtered to just restaurants and converted data to an SF object


```{r read_data}

data <- read.socrata("https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5") %>%
  na.omit() %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326, agr = "constant") %>%
  mutate(inspection_date = ymd(inspection_date),
         year = year(inspection_date),
         address = str_squish(address)) %>%
  st_transform('ESRI:102271') %>%
  mutate(facility_type = str_squish(str_to_title(facility_type)))

#Clean up a bunch of messy facility names to be able to identify just facilities of interest

data$facility_type[grepl("Restaurant", data$facility_type)] <- "Restaurant"
data$facility_type[grepl("Bakery", data$facility_type)] <- "Bakery"
data$facility_type[grepl("Coffee", data$facility_type)] <- "Coffee Shop"
data$facility_type[grepl("Ice Cream", data$facility_type)] <- "Ice Cream Shop"
data$facility_type[grepl("Deli", data$facility_type)] <- "Deli"
data$facility_type[grepl("Taqueria", data$facility_type)] <- "Restaurant"
data$facility_type[grepl("Hot Dog Station", data$facility_type)] <- "Restaurant"
data$facility_type[grepl("Juice and Salad Bar", data$facility_type)] <- "Restaurant"

data$dba_name[grepl("SEE THRU CHINESE", data$dba_name)] <- 'SEE THRU CHINESE RESTAURANT'
data$dba_name[grepl("JAMAICAN  GATES", data$dba_name)] <- 'JAMAICAN GATES'
```

## Read Neighboorhoods Data

```{r neighboorhoods_data}

neighboorhoods <- st_read('https://data.cityofchicago.org/api/geospatial/bbvz-uum9?method=export&format=GeoJSON')%>%
  st_transform('ESRI:102271') %>%
  dplyr::select(pri_neigh)

```


I figured our training data would be one year of data - this is 9,185 data points. I also removed all results which were not Pass or Fail.

```{r training_data}

filter <- c("Restaurant","Bakery","Tavern","Ice Cream Shop","Deli","Cafe","Coffee Shop","")

data_2021 <- data %>%
  dplyr::filter(year == 2021 & results != 'Out of Business' & results != 'No Entry' & results != 'Not Ready') %>%
  dplyr::filter(facility_type %in% filter) %>%
  mutate(results = ifelse(results=="Pass w/ Conditions","Pass",results)) %>%
  st_join(.,neighboorhoods,predicate = st_intersects) %>%
  mutate(pri_neigh = ifelse(location == "(42.008536400868735, -87.91442843927047)","O'Hare",pri_neigh),
         pri_neigh = ifelse(location %in% c("(41.892249163400116, -87.60951804879336)","(41.89233780863412, -87.6040447589981)"),"Streeterville",pri_neigh))

```

## Try to estimate bussiness age

* Establishments that had previous critical or serious violations (based on historical data from 2010 - 2020)

```{r download_liscenses}

#Download all liscences data since 2010, started in 2010 because inspection data does not go back more than 10 years

liscenses <- read.socrata("https://data.cityofchicago.org/resource/r5kz-chrr.json?$where=license_start_date%20between%20%272010-01-01T12:00:00%27%20and%20%272023-12-05T14:00:00%27")

```

```{r clean_data}

#Doing some manual cleaning of address

corrections <- data.frame(
  bad = c("4623-4627 N BROADWAY  1 & 2","100 E WALTON ST 1 104","436-440 E 79TH ST","1733 W 87TH ST 1ST FLOOR","163 E WALTON ST 2ND F","5640 S UNIVERSITY AVE","5255 W MADISON ST 1 B","111 E 51ST ST 1ST`"),
  good = c("4623-4627 N BROADWAY", "100 E WALTON ST","436 - 440 E 79TH ST","1733 W 87TH ST","163 E WALTON ST","5640 S UNIVERSITY","5255 W MADISON ST","111 E 51ST ST 1ST"),
  stringsAsFactors = FALSE
)

liscenses$address <- match_vec(x=liscenses$address,corrections,from=1,to=2, quiet=TRUE)

liscenses$address[grepl("11601 W TOUHY AVE", liscenses$address)] <- "11601 W TOUHY AVE" #Set Everything which contains Chicago O'hare address to just the address

liscenses$address[grepl("47 W POLK ST", liscenses$address)] <- "47 W POLK ST"

liscenses$address <- gsub("\\s*\\d+$", "", liscenses$address) #Remove any trailing numbers

liscenses$address <- gsub("\\s*\\d+(ST)?$", "", liscenses$address) #Remove any trailing numbers which are followed by ST

liscenses$address <- gsub("\\s*\\d+(st)?$", "", liscenses$address) #Remove any trailing numbers which are followed by st

#Standardize some business names

liscenses$doing_business_as_name[grepl("SEE THRU CHINESE", liscenses$doing_business_as_name)] <- 'SEE THRU CHINESE RESTAURANT'
liscenses$doing_business_as_name[grepl("THE NEW VALOIS REST", liscenses$doing_business_as_name)] <- 'THE NEW VALOIS REST INC'
liscenses$doing_business_as_name[grepl("CHICAGO MARRIOTT DOWNTOWN", liscenses$doing_business_as_name)] <- 'CHICAGO DOWNTOWN MARRIOTT'
liscenses$doing_business_as_name[grepl("STAR OF SIAM", liscenses$doing_business_as_name)] <- 'STAR OF SIAM'
liscenses$doing_business_as_name[grepl("EL CHILE RESTAURANT & PANCAKE HOUSE.", liscenses$doing_business_as_name)] <- 'EL CHILE RESTAURANT & PANCAKE HOUSE'
liscenses$doing_business_as_name[grepl("FRANCES' DELI & BRUNCHERY", liscenses$doing_business_as_name)] <- "FRANCES' REST & BRUNCHERY"

```

``` {r determine_age}
#For each for retail establishment determine date when a license was first obtained
liscense_min <- liscenses %>% group_by(doing_business_as_name,address) %>% summarize(min_date = min(license_start_date)) %>%
  arrange(min_date)

#Join min date back to original licence data and select subset of columns 

liscenses_final <- left_join(liscenses, liscense_min , by = c('doing_business_as_name','address')) %>%
  select(license_id, account_number,legal_name,doing_business_as_name,address,site_number,min_date) %>%
  mutate(license_id = as.integer(license_id))

#Join date business applied for first licence to 2021 inspection data - try to joins a variety of different ways since joining on licence number did not match allways

data_2021_2 <- left_join(data_2021,liscenses_final %>% select(license_id,min_date),by=join_by(license_==license_id)) %>%
  rename(min_date1 = 'min_date') %>%
  left_join(.,liscense_min %>% select(doing_business_as_name,address,min_date),by=join_by(dba_name==doing_business_as_name,address==address),multiple='first') %>%
  rename(min_date2 = 'min_date') %>%
  left_join(.,liscense_min %>% select(doing_business_as_name,address,min_date),by=join_by(aka_name==doing_business_as_name,address==address),multiple='first') %>%
  rename(min_date3 = 'min_date') %>%
  mutate(min_date = pmin(min_date1, min_date2, min_date3, na.rm = TRUE), #Select lowest date where multiple joins worked
         age = as.integer(difftime(inspection_date, min_date, units = 'days')))

median(data_2021_2$age,na.rm=TRUE)

data_2021_2 <- data_2021_2 %>%
  mutate(age = ifelse(age<0,0,age),
         age = ifelse(is.na(age),median(age,na.rm=TRUE),age))

median(data_2021_2$age,na.rm=TRUE)
  
```

## Estimate Number of previous violations and join

```{r estimate_failures}

fails <- data %>%
  st_drop_geometry() %>%
  dplyr::filter(year<2021 & results == 'Fail') %>%
  group_by(dba_name,address) %>% tally() %>%
  ungroup() %>%
  rename(prev_fails = 'n')

data_2021_2 <- left_join(data_2021_2,fails,by=join_by(dba_name==dba_name,address==address))

nulls <- data_2021_2 %>% dplyr::filter(is.na(min_date))

```

## Census Wrangling

```{r census_data, results = 'hide'}
variables = c("B17017_002", #Total Households w/ income below poverty line
              "B17017_001", #Total Households 
              "B02001_001", #Total Population
               "B02001_002", #Total White Population
               "B25058_001") #Median Rent

census_data <- get_acs("block group",
        year=2021,
        output='wide',
        geometry=T,
        variables = variables,
        state = 'IL',
        county = 'Cook'
        ) %>%
  st_transform('ESRI:102271') %>%
  select(ends_with('E'),'GEOID') %>%
  rename(poverty = "B17017_001E",
         below_poverty_line = "B17017_002E",
         Total_Population = "B02001_001E",
         White_Population = "B02001_002E",
         Median_Rent = "B25058_001E") %>%
  mutate(Median_Rent = ifelse(is.na(Median_Rent),median(Median_Rent,na.rm=TRUE),Median_Rent),
         pct_white = ifelse(Total_Population == 0,0,White_Population / Total_Population * 100),
         pct_poverty = ifelse(poverty == 0,0, below_poverty_line / poverty * 100)) %>%
  select('Median_Rent','pct_white','pct_poverty','GEOID')
```

Join Census Data to restaurants data

```{r join_censu_data}
data_2021_2 <- data_2021_2 %>%
  st_join(.,census_data,predicate = st_intersects)
```

## Including Plots

Quick Map 1

```{r guick_map1}
ggplot()+
  geom_sf(data=neighboorhoods)+
  geom_sf(data=data_2021,aes(color=results),size=0.5)+
  theme_void()
```

```{r guick_map2}
neigh_summ <- data_2021 %>% st_drop_geometry() %>%
  group_by(pri_neigh,results) %>% tally() %>%
  spread(key=results,value=n) %>%
  mutate(Fail = replace_na(Fail,0),
    pct_pass = Pass / (Fail + Pass) * 100,
    pct_fail = Fail / (Fail + Pass) * 100)%>%
  left_join(neighboorhoods,.,by='pri_neigh') 
  
ggplot()+
  geom_sf(data=neigh_summ,aes(fill=pct_pass))+
  scale_fill_viridis_c(option='rocket')+
  theme_void()
```

```{r guick_chart, fig.width=14}

neigh_summ %>% 
  st_drop_geometry() %>%
  select(pri_neigh,pct_pass,pct_fail) %>%
  gather(pass,rate,-pri_neigh) %>%
  na.omit() %>%
  ggplot(aes(x=pri_neigh,y=rate,fill=pass))+
  geom_bar(position='stack',stat='identity')+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

# Alec's Code Begins Here

```{r chicago_boundary}

chicagoboundary <- 
  st_read("https://data.cityofchicago.org/api/geospatial/ewy2-6yfk?method=export&format=GeoJSON") %>%
  st_transform('ESRI:102271')

```

```{r sanitation_complaints}

sanitation <- st_read("https://data.cityofchicago.org/resource/rccf-5427.geojson") %>%
  st_transform('ESRI:102271') 

```

```{r complaints_visualized, fig.width=9.5, fig.height=4}

grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = chicagoboundary) +
  geom_sf(data = sanitation, colour="blue", size=0.1, show.legend = "point") +
  labs(title= "Sanitation Code Complaints"), 

ggplot() + 
  geom_sf(data = chicagoboundary, fill = "grey80") +
  stat_density2d(data = data.frame(st_coordinates(st_centroid(sanitation))), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Sanitation Code Complaints") +
  theme(legend.position = "none"))
```

```{r rodent_baiting}

rodent <- st_read("https://data.cityofchicago.org/resource/uqhs-j723.geojson")%>%
  st_transform('ESRI:102271') 

```

```{r baiting_visualized, fig.width=9.5, fig.height=4}
grid.arrange(ncol=2,
ggplot() + 
  geom_sf(data = chicagoboundary) +
  geom_sf(data = rodent, colour="blue", size=0.1, show.legend = "point") +
  labs(title= "Rodent Baiting"),

ggplot() + 
  geom_sf(data = chicagoboundary, fill = "grey80") +
  stat_density2d(data = data.frame(st_coordinates(st_centroid(rodent))), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_viridis() +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Rodent Baiting") + 
  theme(legend.position = "none"))
```

```{r}

# Producing a Nearest Neighbor Analysis Between the 2021 Inspection Data and Sanitation Complaints

nearest_sanitation <- st_nearest_feature(data_2021, sanitation)

# Producing a Nearest Neighbor Analysis Between the 2021 Inspection Data and Rodent Baiting

nearest_rodent <- st_nearest_feature(data_2021, rodent)

# Adding the Results as New Columns to the 2021 Inspection Data 

data_2021_with_nearest_sanitation <- cbind(data_2021, nearest_sanitation)

data_2021_with_nearest_rodent <- cbind(data_2021, nearest_rodent)

ggplot() +
  geom_sf(data = chicagoboundary, fill = "grey80") +
  geom_sf(data = data_2021_with_nearest_sanitation, aes(color = nearest_sanitation), size = 0.5) +
  scale_color_viridis() +
  labs(title = "Nearest Neighbors of Sanitation Code Complaints") +
  theme_minimal()

ggplot() +
  geom_sf(data = chicagoboundary, fill = "grey80") +
  geom_sf(data = data_2021_with_nearest_rodent, aes(color = nearest_rodent), size = 0.5) +
  scale_color_viridis() +
  labs(title = "Nearest Neighbors of Rodent Baiting") +
  theme_minimal()

```
